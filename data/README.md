# Training Data

* [FineWeb](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)
  * 15-trillion tokens, 44TB disk space
* Collections
  * [LLM Datasets](https://github.com/mlabonne/llm-datasets)

## Finetune data

* [Alpaca](https://huggingface.co/datasets/yahma/alpaca-cleaned)
